{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Baseline_model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctLlzj0CGXj7",
        "colab_type": "code",
        "outputId": "fabaf583-d6c0-40ff-9236-2751f569695c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from zipfile import ZipFile\n",
        "from io import BytesIO\n",
        "import urllib.request as urllib2\n",
        "\n",
        "import nltk \n",
        "nltk.download('punkt') #to tokenize sentences."
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzNZGc3d7vxg",
        "colab_type": "code",
        "outputId": "872dac24-a06d-4355-d933-72fe4bd2c76e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "r = urllib2.urlopen(\"http://www.cs.cornell.edu/~cristian/data/cornell_movie_dialogs_corpus.zip\").read()\n",
        "file = ZipFile(BytesIO(r))\n",
        "file.extractall()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqs93LzLKnfb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the data\n",
        "lines = open('/content/cornell movie-dialogs corpus/movie_lines.txt', encoding='utf-8', errors='ignore').read().split('\\n')\n",
        "conv_lines = open('/content/cornell movie-dialogs corpus/movie_conversations.txt', encoding='utf-8', errors='ignore').read().split('\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CF44EgIbv6Vt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a dictionary to map each line's id with its text\n",
        "id2line = {}\n",
        "for line in lines:\n",
        "    _line = line.split(' +++$+++ ')\n",
        "    if len(_line) == 5:\n",
        "        id2line[_line[0]] = _line[4]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5olePBLwwHJm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a list of all of the conversations' lines' ids.\n",
        "convs = []\n",
        "for line in conv_lines[:-1]:\n",
        "    _line = line.split(' +++$+++ ')[-1][1:-1].replace(\"'\",\"\").replace(\" \",\"\")\n",
        "    convs.append(_line.split(','))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWJxGENt49SS",
        "colab_type": "code",
        "outputId": "0364eb1a-9ed8-4ba3-eacd-5bb81fd8c0a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "\n",
        "print(id2line['L198'])\n",
        "print(id2line['L199'])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "You're asking me out.  That's so cute. What's your name again?\n",
            "Forget it.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fEc_i8h20Nu",
        "colab_type": "code",
        "outputId": "a882353b-0780-43a1-8ae9-8c48f35aff20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "# Sort the sentences into questions (inputs) and answers (targets)\n",
        "questions = []\n",
        "answers = []\n",
        "for conv in convs:\n",
        "    for i in range(len(conv)-1):\n",
        "        questions.append(id2line[conv[i]])\n",
        "        answers.append(id2line[conv[i+1]])\n",
        "        \n",
        "# Compare lengths of questions and answers\n",
        "print(len(questions))\n",
        "print(len(answers))\n",
        "\n",
        "print(questions[:5])\n",
        "print(answers[:5])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "221616\n",
            "221616\n",
            "['Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again.', \"Well, I thought we'd start with pronunciation, if that's okay with you.\", 'Not the hacking and gagging and spitting part.  Please.', \"You're asking me out.  That's so cute. What's your name again?\", \"No, no, it's my fault -- we didn't have a proper introduction ---\"]\n",
            "[\"Well, I thought we'd start with pronunciation, if that's okay with you.\", 'Not the hacking and gagging and spitting part.  Please.', \"Okay... then how 'bout we try out some French cuisine.  Saturday?  Night?\", 'Forget it.', 'Cameron.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWnEzvM98tjM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#choosing number of training samples\n",
        "num_samples = 10000  #Feel free to change anyone\n",
        "questions_train = questions[:num_samples]\n",
        "answers_train = answers[:num_samples]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKKva3XywPGh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#tokenization for each sentence\n",
        "questions_tok = [nltk.word_tokenize(sent) for sent in questions]\n",
        "#answers_tok = [nltk.word_tokenize(sent) for sent in answers]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "784rtWH96sTe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "full_tok = [item for sublist in questions_tok for item in sublist]\n",
        "full_tok = [x.lower() for x in full_tok]\n",
        "full_tok = [word for word in full_tok if word.isalpha() or word  in ['!','.','?',',']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMe3dN1pMVLO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "b1e8f990-5317-402e-e4e7-bc3d8c4b1eb1"
      },
      "source": [
        "full_tok[:20]"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['can',\n",
              " 'we',\n",
              " 'make',\n",
              " 'this',\n",
              " 'quick',\n",
              " '?',\n",
              " 'roxanne',\n",
              " 'korrine',\n",
              " 'and',\n",
              " 'andrew',\n",
              " 'barrett',\n",
              " 'are',\n",
              " 'having',\n",
              " 'an',\n",
              " 'incredibly',\n",
              " 'horrendous',\n",
              " 'public',\n",
              " 'up',\n",
              " 'on',\n",
              " 'the']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ehYWWuBEzit",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_ngram_lm(data, order=3):\n",
        "    \"\"\"\n",
        "        Train n-gram language model\n",
        "    \"\"\"\n",
        "    \n",
        "    # pad (order-1) special tokens to the left\n",
        "    # for the first token in the text\n",
        "    order -= 1\n",
        "    data = ['<S>'] * order + data #\n",
        "    lm = defaultdict(Counter)\n",
        "    \n",
        "    # get ngrams for all sizes\n",
        "    for k in range(1, order + 2):\n",
        "      \n",
        "      # loop through ngrams to get counts\n",
        "      for i in range(len(data) - k + 1):\n",
        "          \"\"\"\n",
        "          IMPLEMENT ME!\n",
        "\n",
        "          \"\"\"  \n",
        "          # rolling window of ngrams\n",
        "          ngrams = data[i:i + k]\n",
        "          \n",
        "          # split ngrams into previous word and next word\n",
        "          next_word = ngrams.pop()\n",
        "          \n",
        "          # concatenate previous words with space\n",
        "          ngrams = \" \".join(ngrams)\n",
        "\n",
        "          # add count of next word in ngram\n",
        "          lm[ngrams].update([next_word])\n",
        "\n",
        "    # convert Counter() object to dict\n",
        "    lm = {key:  dict(values) for key, values in lm.items()}\n",
        "\n",
        "    # normalize by counts\n",
        "    for i in lm.keys():\n",
        "      total = sum(lm[i].values(), 0.0)\n",
        "      lm[i] = {k: v / total for k, v in lm[i].items()}\n",
        "    return lm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ko8gTBPCFAGI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch, pickle, os, sys, random, time\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from torch import nn, optim\n",
        "from collections import *\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hm4ensRFRKZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# generate text\n",
        "def generate_text(lm, vocab, context=\"he is the\", order=3, num_tok=10):\n",
        "    \n",
        "    # The goal is to generate new words following the context\n",
        "    # If context has more tokens than the order of lm, \n",
        "    # generate text that follows the last (order-1) tokens of the context\n",
        "    # and store it in the variable `history`\n",
        "    order -= 1\n",
        "    history = context.split()[-order:]\n",
        "    \n",
        "    \n",
        "    # `out` is the list of tokens of context\n",
        "    # you need to append the generated tokens to this list\n",
        "    out = context.split()\n",
        "    punctuation = 0\n",
        "    \n",
        "    while punctuation < 2:\n",
        "        \"\"\"\n",
        "        IMPLEMENT ME!\n",
        "        \n",
        "        \"\"\"\n",
        "        # if the context word has more tokens than the order of lm\n",
        "        if len(history) > order:\n",
        "          history = history[-(order - 1):]\n",
        "          \n",
        "        # for unigram models\n",
        "        if order == 0:\n",
        "          history = []\n",
        "        \n",
        "        # concatenate history with space\n",
        "        context = \" \".join(history)\n",
        "\n",
        "        # look up context distribution\n",
        "        dist = lm[context]\n",
        "        \n",
        "        # find next word from distribution\n",
        "        next_word = list(np.random.choice(list(dist.keys()), 1, list(dist.values())))\n",
        "        \n",
        "        # only output the first two sentences\n",
        "        if next_word[0] in ['.','!','?']:\n",
        "          punctuation += 1\n",
        "        \n",
        "        # append next word to out\n",
        "        out += next_word\n",
        "       \n",
        "        # update history\n",
        "        history = history[1:]\n",
        "        history += next_word\n",
        "    \n",
        "    return \" \".join(out[3:])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5UilbWcFlx3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "order = 4\n",
        "vocab = list(set(full_tok))\n",
        "model = train_ngram_lm(full_tok, order=order)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mx32PfQMFtND",
        "colab_type": "code",
        "outputId": "4865c1e9-d1e7-4787-ad66-49549a1b049d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        }
      },
      "source": [
        "generate_text(model, vocab, context='he is the', order=order)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['he', 'is', 'the']\n",
            "courageous\n",
            "captain\n",
            "of\n",
            "compliments\n",
            ".\n",
            "he\n",
            "fights\n",
            "as\n",
            "you\n",
            "sing\n",
            "song\n",
            ",\n",
            "keeps\n",
            "time\n",
            ",\n",
            "distance\n",
            ",\n",
            "and\n",
            "proportion\n",
            "he\n",
            "rests\n",
            "his\n",
            "minim\n",
            "rest\n",
            ",\n",
            "one\n",
            ",\n",
            "i\n",
            "spare\n",
            "no\n",
            "expense\n",
            ".\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'courageous captain of compliments . he fights as you sing song , keeps time , distance , and proportion he rests his minim rest , one , i spare no expense .'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_rYsVtbGVVd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def chat_with_chatbot():\n",
        "  firstrun = 0\n",
        "  while True:\n",
        "      if firstrun == 0:\n",
        "        print(\"Hello my name is dumb chatbot! Let's chat but I may not make much sense. Type goodbye to exit.\")\n",
        "        firstrun +=1\n",
        "\n",
        "      response = str(input())\n",
        "      response_tok = nltk.word_tokenize(response)\n",
        "      response_tok = [x.lower() for x in response_tok]\n",
        "      response = \" \".join(response_tok)\n",
        "      if response == \"goodbye\":\n",
        "          break\n",
        "      else:\n",
        "        try:\n",
        "          print(generate_text(model, vocab, context=response, order=order))\n",
        "        except:\n",
        "          print(\"sorry, I couldn't understand that!\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjde6i2xIQFa",
        "colab_type": "code",
        "outputId": "824e1d66-c1f5-4bc5-f753-589e3ba4abbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "chat_with_chatbot()"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hello my name is dumb chatbot! Let's chat but I may not make much sense. Type goodbye to exit.\n",
            "How are you?\n",
            "? nuts ? you bastard !\n",
            "why are you nuts!?\n",
            "sorry, I couldn't understand that!\n",
            "why not?\n",
            "how much for the tour of our humble plant . i must deactivate you .\n",
            "That is mean!\n",
            "sorry, I couldn't understand that!\n",
            "I am angry.\n",
            "sorry, I couldn't understand that!\n",
            "why!\n",
            "has , but ai i got melanie in hermosa beach . she tells me these answers , right place ?\n",
            "no.\n",
            "do . eating ?\n",
            "goodbye\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}