{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"https://katiehouse3.pythonanywhere.com/static/moviechat/img/movie.png\" width=\"25px\" align=\"left\">\n",
    "\n",
    "<h1>Finetune Hollybot GPT-2 on Microsoft Azure</h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script will use Microsoft Azure's amlcompute to finetune Hollybot's [GPT-2 transformer model](https://huggingface.co/transformers/model_doc/gpt2.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Hollybot ?\n",
    "Hollybot is a chatbot trained on over 220,579 conversations from movie scripts. The end result is a chatbot that learns the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDK version: 1.0.62\n"
     ]
    }
   ],
   "source": [
    "# Check core SDK version number\n",
    "import azureml.core\n",
    "\n",
    "print(\"SDK version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turning diagnostics collection on. \n"
     ]
    }
   ],
   "source": [
    "from azureml.telemetry import set_diagnostics_collection\n",
    "\n",
    "set_diagnostics_collection(send_diagnostics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.workspace import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Resource group: ' + ws.resource_group, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./pytorch-gpt2/dialogue_data.pkl'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "project_folder = './pytorch-gpt2'\n",
    "os.makedirs(project_folder, exist_ok=True)\n",
    "shutil.copy('processed_data_final.csv', project_folder)\n",
    "shutil.copy('dialogue_data.pkl', project_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndatastore = Datastore.register_azure_blob_container(workspace=ws, \\n                                                      datastore_name=\"gpt2training\",\\n                                                        account_name=\"amherstwstorageinnganzr\",\\n                                                    container_name=\"gpt2training\", \\n                                                      account_key=\\'<MY ACCOUNT KEY>\\',\\n                                                      create_if_not_exists=True)\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "datastore = Datastore.register_azure_blob_container(workspace=ws, \n",
    "                                                      datastore_name=\"gpt2training\",\n",
    "                                                        account_name=\"amherstwstorageinnganzr\",\n",
    "                                                    container_name=\"gpt2training\", \n",
    "                                                      account_key='<MY ACCOUNT KEY>',\n",
    "                                                      create_if_not_exists=True)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading an estimated of 2 files\n",
      "Uploading ./pytorch-gpt2/dialogue_data.pkl\n",
      "Uploading ./pytorch-gpt2/processed_data_final.csv\n",
      "Uploaded ./pytorch-gpt2/processed_data_final.csv, 1 files out of an estimated total of 2\n",
      "Uploaded ./pytorch-gpt2/processed_data_final.csv, 1 files out of an estimated total of 2\n",
      "Uploaded ./pytorch-gpt2/dialogue_data.pkl, 2 files out of an estimated total of 2\n",
      "Uploaded 2 files\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "$AZUREML_DATAREFERENCE_0e7399f6908d4f1dbe15d7c726feba64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded ./pytorch-gpt2/dialogue_data.pkl, 2 files out of an estimated total of 2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import azureml.data\n",
    "from azureml.data.azure_storage_datastore import AzureFileDatastore, AzureBlobDatastore\n",
    "datastore = Datastore.get(ws, datastore_name='gpt2training')\n",
    "\n",
    "datastore.upload(src_dir='./pytorch-gpt2',\n",
    "                 target_path='pytorch-gpt2',\n",
    "                 overwrite=True,\n",
    "                 show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are your availible datastores...\n",
      "workspaceblobstore AzureBlob\n",
      "workspacefilestore AzureFile\n",
      "commercial_blocks AzureBlob\n",
      "machine_translation AzureBlob\n",
      "commercialblockclassification AzureBlob\n",
      "gpt2training AzureBlob\n"
     ]
    }
   ],
   "source": [
    "print(\"These are your availible datastores...\")\n",
    "import azureml.core\n",
    "from azureml.core import Workspace, Datastore\n",
    "datastores = ws.datastores\n",
    "for name, ds in datastores.items():\n",
    "    print(name, ds.datastore_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get named datastore from current workspace\n",
    "datastore = Datastore.get(ws, datastore_name='gpt2training')\n",
    "ws.set_default_datastore('gpt2training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "$AZUREML_DATAREFERENCE_gpt2training"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datastore.as_mount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating\n",
      "Succeeded..............\n",
      "AmlCompute wait for completion finished\n",
      "Minimum number of nodes requested have been provisioned\n",
      "{'currentNodeCount': 2, 'targetNodeCount': 2, 'nodeStateCounts': {'preparingNodeCount': 2, 'runningNodeCount': 0, 'idleNodeCount': 0, 'unusableNodeCount': 0, 'leavingNodeCount': 0, 'preemptedNodeCount': 0}, 'allocationState': 'Steady', 'allocationStateTransitionTime': '2019-12-08T23:38:09.692000+00:00', 'errors': None, 'creationTime': '2019-12-08T23:36:34.117992+00:00', 'modifiedTime': '2019-12-08T23:36:51.443726+00:00', 'provisioningState': 'Succeeded', 'provisioningStateTransitionTime': None, 'scaleSettings': {'minNodeCount': 2, 'maxNodeCount': 4, 'nodeIdleTimeBeforeScaleDown': 'PT120S'}, 'vmPriority': 'Dedicated', 'vmSize': 'STANDARD_NC24'}\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "# choose a name for your cluster\n",
    "cluster_name = \"gpu-cluster\"\n",
    "\n",
    "'''\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    compute_target.delete()\n",
    "    print('Found existing compute target.')\n",
    "except ComputeTargetException:\n",
    "    print('Creating a new compute target...')\n",
    "    \n",
    "'''\n",
    "compute_config = AmlCompute.provisioning_configuration(vm_size='Standard_NC24', min_nodes=2, \n",
    "                                                       max_nodes=4)\n",
    "\n",
    "# create the cluster\n",
    "compute_target = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "\n",
    "compute_target.wait_for_completion(show_output=True)\n",
    "\n",
    "# use get_status() to get a detailed status for the current cluster. \n",
    "print(compute_target.get_status().serialize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "\n",
    "experiment_name = 'pytorch-gpt2'\n",
    "experiment = Experiment(ws, name=experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./train-on-amlcompute/processed_data_final.csv'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "project_folder = './train-on-amlcompute'\n",
    "os.makedirs(project_folder, exist_ok=True)\n",
    "shutil.copy('train.py', project_folder)\n",
    "shutil.copy('processed_data_final.csv', project_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "myenv = Environment(\"myenv\")\n",
    "\n",
    "myenv.docker.enabled = True\n",
    "myenv.python.conda_dependencies = CondaDependencies.create(pip_packages=['utils','torch','tensorflow','azureml-sdk','argparse','pandas','numpy','transformers', 'scikit-learn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - 'gpu_support' is no longer necessary; AzureML now automatically detects and uses nvidia docker extension when it is available. It will be removed in a future release.\n",
      "WARNING - 'gpu_support' is no longer necessary; AzureML now automatically detects and uses nvidia docker extension when it is available. It will be removed in a future release.\n",
      "WARNING - framework_version is not specified, defaulting to version 1.2.\n",
      "WARNING - 'gpu_support' is no longer necessary; AzureML now automatically detects and uses nvidia docker extension when it is available. It will be removed in a future release.\n"
     ]
    }
   ],
   "source": [
    "from azureml.train.dnn import PyTorch\n",
    "\n",
    "script_params = {\n",
    "    '--data_dir': datastore.path('/pytorch-gpt2').as_mount(),\n",
    "    '--output_dir': './outputs'\n",
    "}\n",
    "\n",
    "\n",
    "estimator = PyTorch(source_directory=project_folder, \n",
    "                    script_params=script_params,\n",
    "                    compute_target=compute_target,\n",
    "                    entry_script='train.py',\n",
    "                    use_gpu=True,\n",
    "                    inputs=[datastore.path('/gpt2training').as_download(),datastore.as_mount()],\n",
    "                    pip_packages=['pillow==5.4.1','git+https://github.com/huggingface/transformers'])\n",
    "\n",
    "\n",
    "# Set environment\n",
    "estimator.run_config.environment = myenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - 'gpu_support' is no longer necessary; AzureML now automatically detects and uses nvidia docker extension when it is available. It will be removed in a future release.\n",
      "Submitting /Users/katiehouse/Documents/github/chatbot-with-personality-2/models/train-on-amlcompute directory for run. The size of the directory >= 25 MB, so it can take a few minutes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run(Experiment: pytorch-gpt2,\n",
      "Id: pytorch-gpt2_1575848361_16f023ca,\n",
      "Type: azureml.scriptrun,\n",
      "Status: Queued)\n"
     ]
    }
   ],
   "source": [
    "run = experiment.submit(estimator)\n",
    "print(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'runId': 'pytorch-gpt2_1575848361_16f023ca', 'target': 'gpu-cluster', 'status': 'Queued', 'properties': {'_azureml.ComputeTargetType': 'amlcompute', 'ContentSnapshotId': '1f225141-f143-4e85-876f-6e0a3534da15', 'azureml.git.repository_uri': 'https://github.com/katiehouse3/chatbot-with-personality.git', 'mlflow.source.git.repoURL': 'https://github.com/katiehouse3/chatbot-with-personality.git', 'azureml.git.commit': 'd1a23dbb7f90d7638eb419b6bb98d8a4a2b0c2a4', 'mlflow.source.git.commit': 'd1a23dbb7f90d7638eb419b6bb98d8a4a2b0c2a4', 'azureml.git.dirty': 'True', 'AzureML.DerivedImageName': 'azureml/azureml_17c5d7f9f15131cc7ae45d39982e34c8', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}, 'runDefinition': {'script': 'train.py', 'arguments': ['--data_dir', '$AZUREML_DATAREFERENCE_a327617aecfa4f2a89468c63e534ddd3', '--output_dir', './outputs'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'gpu-cluster', 'dataReferences': {'5b430d0516f24559835c42876601a2f9': {'dataStoreName': 'gpt2training', 'mode': 'Download', 'pathOnDataStore': '/gpt2training', 'pathOnCompute': None, 'overwrite': False}, 'gpt2training': {'dataStoreName': 'gpt2training', 'mode': 'Mount', 'pathOnDataStore': None, 'pathOnCompute': None, 'overwrite': False}, 'a327617aecfa4f2a89468c63e534ddd3': {'dataStoreName': 'gpt2training', 'mode': 'Mount', 'pathOnDataStore': '/pytorch-gpt2', 'pathOnCompute': None, 'overwrite': False}}, 'data': {}, 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'environment': {'name': 'myenv', 'version': 'Autosave_2019-12-08T16:14:13Z_e0c92167', 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'channels': ['conda-forge'], 'dependencies': ['python=3.6.2', {'pip': ['utils', 'torch', 'tensorflow', 'azureml-sdk==1.0.62.*', 'argparse', 'pandas', 'numpy', 'transformers', 'scikit-learn']}], 'name': 'azureml_2b84c039ac992816da58ce775b0740b9'}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/base:intelmpi2018.3-ubuntu16.04', 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': True, 'arguments': []}, 'spark': {'repositories': [], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs'], 'snapshotProject': True}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': True, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}}, 'logFiles': {}}\n"
     ]
    }
   ],
   "source": [
    "print(run.get_details())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2e76f42b47443d49e6021d3e79da4e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>_UserRunWidget</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': True, 'log_level': 'INFO', 'sdk_version': '1.0.62'})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
