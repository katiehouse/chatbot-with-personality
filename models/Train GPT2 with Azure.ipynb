{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDK version: 1.0.62\n"
     ]
    }
   ],
   "source": [
    "# Check core SDK version number\n",
    "import azureml.core\n",
    "\n",
    "print(\"SDK version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turning diagnostics collection on. \n"
     ]
    }
   ],
   "source": [
    "from azureml.telemetry import set_diagnostics_collection\n",
    "\n",
    "set_diagnostics_collection(send_diagnostics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workspace name: AmherstWorkspace\n",
      "Azure region: eastus2\n",
      "Subscription id: a989cac4-671d-45c6-9d2b-ea7e9d936600\n",
      "Resource group: AmherstRG\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.workspace import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Subscription id: ' + ws.subscription_id, \n",
    "      'Resource group: ' + ws.resource_group, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import azureml._restclient.snapshots_client\n",
    "#azureml._restclient.snapshots_client.SNAPSHOT_MAX_SIZE_BYTES = '1000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndatastore = Datastore.register_azure_blob_container(workspace=ws, \\n                                                      datastore_name=\"gpt2training\",\\n                                                        account_name=\"amherstwstorageinnganzr\",\\n                                                    container_name=\"gpt2training\", \\n                                                      account_key=\\'DSmRA/zspF6JzGlu7Od4h4foh1qh/nUSi7KKeJGKfKrVLOA7e/5UdE/kGRPrLDprvmSTwG+6uuOKIhIjyejgPQ==\\',\\n                                                      create_if_not_exists=True)\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "datastore = Datastore.register_azure_blob_container(workspace=ws, \n",
    "                                                      datastore_name=\"gpt2training\",\n",
    "                                                        account_name=\"amherstwstorageinnganzr\",\n",
    "                                                    container_name=\"gpt2training\", \n",
    "                                                      account_key='<MY ACCOUNT KEY>',\n",
    "                                                      create_if_not_exists=True)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nimport azureml.data\\nfrom azureml.data.azure_storage_datastore import AzureFileDatastore, AzureBlobDatastore\\n\\ndatastore.upload(src_dir='./pytorch-gpt2',\\n                 target_path='pytorch-gpt2',\\n                 overwrite=True,\\n                 show_progress=True)\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import azureml.data\n",
    "from azureml.data.azure_storage_datastore import AzureFileDatastore, AzureBlobDatastore\n",
    "\n",
    "datastore.upload(src_dir='./pytorch-gpt2',\n",
    "                 target_path='pytorch-gpt2',\n",
    "                 overwrite=True,\n",
    "                 show_progress=True)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are your availible datastores...\n",
      "workspaceblobstore AzureBlob\n",
      "workspacefilestore AzureFile\n",
      "commercial_blocks AzureBlob\n",
      "machine_translation AzureBlob\n",
      "commercialblockclassification AzureBlob\n",
      "gpt2training AzureBlob\n"
     ]
    }
   ],
   "source": [
    "print(\"These are your availible datastores...\")\n",
    "import azureml.core\n",
    "from azureml.core import Workspace, Datastore\n",
    "datastores = ws.datastores\n",
    "for name, ds in datastores.items():\n",
    "    print(name, ds.datastore_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get named datastore from current workspace\n",
    "datastore = Datastore.get(ws, datastore_name='gpt2training')\n",
    "ws.set_default_datastore('gpt2training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "$AZUREML_DATAREFERENCE_gpt2training"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datastore.as_mount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing compute target.\n",
      "{'currentNodeCount': 1, 'targetNodeCount': 1, 'nodeStateCounts': {'preparingNodeCount': 0, 'runningNodeCount': 1, 'idleNodeCount': 0, 'unusableNodeCount': 0, 'leavingNodeCount': 0, 'preemptedNodeCount': 0}, 'allocationState': 'Steady', 'allocationStateTransitionTime': '2019-12-08T17:07:54.356000+00:00', 'errors': None, 'creationTime': '2019-12-07T19:32:34.520354+00:00', 'modifiedTime': '2019-12-07T19:32:50.537541+00:00', 'provisioningState': 'Succeeded', 'provisioningStateTransitionTime': None, 'scaleSettings': {'minNodeCount': 0, 'maxNodeCount': 4, 'nodeIdleTimeBeforeScaleDown': 'PT120S'}, 'vmPriority': 'Dedicated', 'vmSize': 'STANDARD_NC6'}\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "# choose a name for your cluster\n",
    "cluster_name = \"gpu-cluster\"\n",
    "\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing compute target.')\n",
    "except ComputeTargetException:\n",
    "    print('Creating a new compute target...')\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='Standard_NC24r', \n",
    "                                                           max_nodes=4)\n",
    "\n",
    "    # create the cluster\n",
    "    compute_target = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "\n",
    "    compute_target.wait_for_completion(show_output=True)\n",
    "\n",
    "# use get_status() to get a detailed status for the current cluster. \n",
    "print(compute_target.get_status().serialize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "\n",
    "experiment_name = 'pytorch-gpt2'\n",
    "experiment = Experiment(ws, name=experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./train-on-amlcompute/processed_data_final.csv'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "project_folder = './train-on-amlcompute'\n",
    "os.makedirs(project_folder, exist_ok=True)\n",
    "shutil.copy('train.py', project_folder)\n",
    "shutil.copy('processed_data_final.csv', project_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "myenv = Environment(\"myenv\")\n",
    "\n",
    "myenv.docker.enabled = True\n",
    "myenv.python.conda_dependencies = CondaDependencies.create(pip_packages=['utils','torch','tensorflow','azureml-sdk','argparse','pandas','numpy','transformers', 'scikit-learn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - 'gpu_support' is no longer necessary; AzureML now automatically detects and uses nvidia docker extension when it is available. It will be removed in a future release.\n",
      "WARNING - 'gpu_support' is no longer necessary; AzureML now automatically detects and uses nvidia docker extension when it is available. It will be removed in a future release.\n",
      "WARNING - framework_version is not specified, defaulting to version 1.2.\n",
      "WARNING - 'gpu_support' is no longer necessary; AzureML now automatically detects and uses nvidia docker extension when it is available. It will be removed in a future release.\n"
     ]
    }
   ],
   "source": [
    "from azureml.train.dnn import PyTorch\n",
    "\n",
    "script_params = {\n",
    "    '--data_dir': datastore.path('/pytorch-gpt2').as_mount(),\n",
    "    '--output_dir': './outputs'\n",
    "}\n",
    "\n",
    "\n",
    "estimator = PyTorch(source_directory=project_folder, \n",
    "                    script_params=script_params,\n",
    "                    compute_target=compute_target,\n",
    "                    entry_script='train.py',\n",
    "                    use_gpu=True,\n",
    "                    inputs=[datastore.path('/gpt2training').as_download(),datastore.as_mount()],\n",
    "                    pip_packages=['pillow==5.4.1','git+https://github.com/huggingface/transformers'])\n",
    "\n",
    "\n",
    "# Set environment\n",
    "estimator.run_config.environment = myenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - 'gpu_support' is no longer necessary; AzureML now automatically detects and uses nvidia docker extension when it is available. It will be removed in a future release.\n",
      "Submitting /Users/katiehouse/Documents/github/chatbot-with-personality/models/train-on-amlcompute directory for run. The size of the directory >= 25 MB, so it can take a few minutes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run(Experiment: pytorch-gpt2,\n",
      "Id: pytorch-gpt2_1575828353_e104bdef,\n",
      "Type: azureml.scriptrun,\n",
      "Status: Queued)\n"
     ]
    }
   ],
   "source": [
    "run = experiment.submit(estimator)\n",
    "print(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'runId': 'pytorch-gpt2_1575776290_3f40e08b', 'target': 'gpu-cluster', 'status': 'Preparing', 'properties': {'_azureml.ComputeTargetType': 'amlcompute', 'ContentSnapshotId': '894b4c29-e814-40e4-ba65-53eb059ea028', 'azureml.git.repository_uri': 'https://github.com/katiehouse3/chatbot-with-personality.git', 'mlflow.source.git.repoURL': 'https://github.com/katiehouse3/chatbot-with-personality.git', 'azureml.git.branch': 'master', 'mlflow.source.git.branch': 'master', 'azureml.git.commit': '4e4b7f81f96a0d9eb7aa8eed80d1b4109efb8beb', 'mlflow.source.git.commit': '4e4b7f81f96a0d9eb7aa8eed80d1b4109efb8beb', 'azureml.git.dirty': 'True', 'AzureML.DerivedImageName': 'azureml/azureml_37d0328ca2737bfe8f22a331c771782c'}, 'runDefinition': {'script': 'train.py', 'arguments': ['--data_dir', '$AZUREML_DATAREFERENCE_4e83ae4cf64b47f88cb0396be01fb43b'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'gpu-cluster', 'dataReferences': {'4e83ae4cf64b47f88cb0396be01fb43b': {'dataStoreName': 'gpt2training', 'mode': 'Mount', 'pathOnDataStore': '/pytorch-gpt2', 'pathOnCompute': None, 'overwrite': False}}, 'data': {}, 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'environment': {'name': 'myenv', 'version': 'Autosave_2019-12-08T03:38:11Z_9cb782de', 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'channels': ['conda-forge'], 'dependencies': ['python=3.6.2', {'pip': ['utils', 'glob', 'torch', 'tensorflow', 'azureml-sdk==1.0.62.*', 'argparse', 'pandas', 'numpy', 'transformers', 'scikit-learn']}], 'name': 'azureml_243c3df6dbfdf009a3920d50930dafce'}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/base:intelmpi2018.3-ubuntu16.04', 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': True, 'arguments': []}, 'spark': {'repositories': [], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs'], 'snapshotProject': True}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': True, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}}, 'logFiles': {'azureml-logs/20_image_build_log.txt': 'https://amherstwstorageinnganzr.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-gpt2_1575776290_3f40e08b/azureml-logs/20_image_build_log.txt?sv=2019-02-02&sr=b&sig=%2B9BI2b%2B1kZabzUKMs08693iRUc8FaJR9nz6LGwaqmYE%3D&st=2019-12-08T03%3A29%3A28Z&se=2019-12-08T11%3A39%3A28Z&sp=r'}}\n"
     ]
    }
   ],
   "source": [
    "print(run.get_details())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e8338efa7764cfca339223423a83113",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>_UserRunWidget</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': True, 'log_level': 'INFO', 'sdk_version': '1.0.62'})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
